import gradio as gr
import requests
import base64
from PIL import Image
from io import BytesIO

def decode_image(base64_image: str) -> str:
	im = Image.open(BytesIO(base64.b64decode(base64_image)))
	return im

def refresh_image():
	response = requests.get("http://127.0.0.1:8000/image/json/").json()
	base64_image = response["base64"]
	image = decode_image(base64_image)
	return response["id"], response["description"], image

def get_similarity(actual_description, description_guess):
	return int(actual_description == description_guess)

def get_frontend():
	with gr.Blocks() as demo:
		with gr.Row():
			introduction = gr.Markdown("""
				# Reverse pictionary

				An AI generated picture is presented to you on the left hand 
				side. Your task is to guess, which query was used to generate that 
				image. Your submission will be scored against the true image and
				the query similarity, as measured by another AI model is returned.

				The pictures were generated by either DALL-E or by the Stable 
				Diffusion model. The text similarity is measured a sentence 
				transformer model from te huggingface hub "sentence-transformers/all-MiniLM-L6-v2"
			""")
		with gr.Row():
			with gr.Column(scale=1):
				__, _, im = refresh_image()
				candidate_image = gr.Image(im ,type="pil", shape=(20,20))
			with gr.Column(scale=2):
				id = gr.Textbox(label="Id", visible=False)
				actual_description = gr.Textbox(label="Actual description", visible=False)
				description_guess = gr.Textbox(label="Image description guess")
				similarity_score = gr.Number(label="Similarity score")
				new_image = gr.Button("Get new image")
				new_image.click(fn=refresh_image, inputs=None, outputs=[id, actual_description, candidate_image])
				submit = gr.Button("Submit")
				submit.click(fn=get_similarity, inputs=[actual_description, description_guess], outputs=similarity_score)
	demo.launch()
	return demo

frontend = get_frontend()
